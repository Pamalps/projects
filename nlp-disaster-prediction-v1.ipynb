{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-03T21:22:14.774238Z","iopub.execute_input":"2022-04-03T21:22:14.774523Z","iopub.status.idle":"2022-04-03T21:22:14.782834Z","shell.execute_reply.started":"2022-04-03T21:22:14.774494Z","shell.execute_reply":"2022-04-03T21:22:14.781866Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#Import the libraries\nfrom sklearn.model_selection import train_test_split    # Splits arrays or matrices into random train and test subsets\nfrom sklearn.model_selection import KFold               # Cross-validator\nfrom sklearn.model_selection import cross_validate      # Evaluate metrics by cross-validation\nfrom sklearn.model_selection import GridSearchCV        # Search over specified parameter values for an estimator\nfrom sklearn.compose import ColumnTransformer           # Applies transformers to columns of DataFrames\nfrom sklearn.pipeline import Pipeline                   # Helps building a chain of transforms and estimators\nfrom sklearn.impute import SimpleImputer                # Imputation transformer for completing missing values\nfrom sklearn.preprocessing import OneHotEncoder         # Encode categorical features","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:22:49.271820Z","iopub.execute_input":"2022-04-03T21:22:49.273358Z","iopub.status.idle":"2022-04-03T21:22:50.733314Z","shell.execute_reply.started":"2022-04-03T21:22:49.273292Z","shell.execute_reply":"2022-04-03T21:22:50.732359Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Import the csv files","metadata":{}},{"cell_type":"code","source":"df_train=pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\", index_col='id')\ndf_test=pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\", index_col='id')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:23:02.141932Z","iopub.execute_input":"2022-04-03T21:23:02.142253Z","iopub.status.idle":"2022-04-03T21:23:02.245737Z","shell.execute_reply.started":"2022-04-03T21:23:02.142217Z","shell.execute_reply":"2022-04-03T21:23:02.244331Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"The dataset provided has been split into train and test datasets. \nThe train dataset has 7613 rows and 4 columns. The target column is part of the train dataset.\nThe test dataset has 3263 rows and 3 columns. the target column is not part of the test dataset, and needs to be predicted and submitted as part of the competition.","metadata":{}},{"cell_type":"code","source":"print(\"size of train dataset\",df_train.shape)\nprint(\"size of test dataset\",df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:24:09.162601Z","iopub.execute_input":"2022-04-03T21:24:09.162923Z","iopub.status.idle":"2022-04-03T21:24:09.171369Z","shell.execute_reply.started":"2022-04-03T21:24:09.162892Z","shell.execute_reply":"2022-04-03T21:24:09.170200Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"size of train dataset (7613, 4)\nsize of test dataset (3263, 3)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(3263, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Test train split","metadata":{}},{"cell_type":"markdown","source":"Our model is to be developed on the provided train dataset. So we further split train dataset into train and validation datasets to create and validate different models.","metadata":{}},{"cell_type":"markdown","source":"### Split the train dataset into predictor and response variables","metadata":{}},{"cell_type":"code","source":"X = df_train.iloc[:,:-1] #the predictor columns are all columns except the target column\ny = df_train.iloc[:,-1:] #the target column is the last column ","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:28:41.135976Z","iopub.execute_input":"2022-04-03T21:28:41.136716Z","iopub.status.idle":"2022-04-03T21:28:41.144392Z","shell.execute_reply.started":"2022-04-03T21:28:41.136669Z","shell.execute_reply":"2022-04-03T21:28:41.143431Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, \n                                                                train_size=0.8, \n                                                                test_size=0.2, \n                                                                random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:28:42.687625Z","iopub.execute_input":"2022-04-03T21:28:42.688212Z","iopub.status.idle":"2022-04-03T21:28:42.697374Z","shell.execute_reply.started":"2022-04-03T21:28:42.688161Z","shell.execute_reply":"2022-04-03T21:28:42.696687Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"size of X_train: predictors\",X_train_full.shape)\nprint(\"size of X_valid: predictors\",X_valid_full.shape)\nprint(\"size of y_train: response\",y_train.shape)\nprint(\"size of y_valid: response\",y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:31:06.928291Z","iopub.execute_input":"2022-04-03T21:31:06.928596Z","iopub.status.idle":"2022-04-03T21:31:06.937370Z","shell.execute_reply.started":"2022-04-03T21:31:06.928564Z","shell.execute_reply":"2022-04-03T21:31:06.936048Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"size of X_train: predictors (6090, 3)\nsize of X_valid: predictors (1523, 3)\nsize of y_train: response (6090, 1)\nsize of y_valid: response (1523, 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"Exploratory analysis on our new training dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:32:27.741118Z","iopub.execute_input":"2022-04-03T21:32:27.741747Z","iopub.status.idle":"2022-04-03T21:32:27.748495Z","shell.execute_reply.started":"2022-04-03T21:32:27.741685Z","shell.execute_reply":"2022-04-03T21:32:27.747060Z"}}},{"cell_type":"code","source":"X_train_full.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:32:41.651592Z","iopub.execute_input":"2022-04-03T21:32:41.652414Z","iopub.status.idle":"2022-04-03T21:32:41.679529Z","shell.execute_reply.started":"2022-04-03T21:32:41.652366Z","shell.execute_reply":"2022-04-03T21:32:41.678524Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 6090 entries, 1999 to 3924\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   keyword   6044 non-null   object\n 1   location  4075 non-null   object\n 2   text      6090 non-null   object\ndtypes: object(3)\nmemory usage: 190.3+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"We see that location and keywords have some nulls.","metadata":{}},{"cell_type":"markdown","source":"## check the balance of the dataset","metadata":{}},{"cell_type":"code","source":"y_train.groupby(['target']).size()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:46:13.754424Z","iopub.execute_input":"2022-04-03T21:46:13.755300Z","iopub.status.idle":"2022-04-03T21:46:13.764300Z","shell.execute_reply.started":"2022-04-03T21:46:13.755111Z","shell.execute_reply":"2022-04-03T21:46:13.763363Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"target\n0    3456\n1    2634\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"So we see that its a well balanced dataset.","metadata":{}},{"cell_type":"markdown","source":"## check examples of disaster and non disaster tweets","metadata":{}},{"cell_type":"code","source":"df_train[df_train['target']==0].head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:52:03.326295Z","iopub.execute_input":"2022-04-03T21:52:03.326639Z","iopub.status.idle":"2022-04-03T21:52:03.344409Z","shell.execute_reply.started":"2022-04-03T21:52:03.326599Z","shell.execute_reply":"2022-04-03T21:52:03.343220Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   keyword location                          text  target\nid                                                       \n23     NaN      NaN                What's up man?       0\n24     NaN      NaN                 I love fruits       0\n25     NaN      NaN              Summer is lovely       0\n26     NaN      NaN             My car is so fast       0\n28     NaN      NaN  What a goooooooaaaaaal!!!!!!       0\n31     NaN      NaN        this is ridiculous....       0\n32     NaN      NaN             London is cool ;)       0\n33     NaN      NaN                   Love skiing       0\n34     NaN      NaN         What a wonderful day!       0\n36     NaN      NaN                      LOOOOOOL       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>What's up man?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I love fruits</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Summer is lovely</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>My car is so fast</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>What a goooooooaaaaaal!!!!!!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>this is ridiculous....</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>London is cool ;)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Love skiing</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>What a wonderful day!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LOOOOOOL</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train[df_train['target']==1].head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T21:52:23.788577Z","iopub.execute_input":"2022-04-03T21:52:23.788933Z","iopub.status.idle":"2022-04-03T21:52:23.806624Z","shell.execute_reply.started":"2022-04-03T21:52:23.788889Z","shell.execute_reply":"2022-04-03T21:52:23.805253Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"   keyword location                                               text  target\nid                                                                            \n1      NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n4      NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n5      NaN      NaN  All residents asked to 'shelter in place' are ...       1\n6      NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n7      NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1\n8      NaN      NaN  #RockyFire Update => California Hwy. 20 closed...       1\n10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...       1\n13     NaN      NaN  I'm on top of the hill and I can see a fire in...       1\n14     NaN      NaN  There's an emergency evacuation happening now ...       1\n15     NaN      NaN  I'm afraid that the tornado is coming to our a...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#flood #disaster Heavy rain causes flash flood...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I'm on top of the hill and I can see a fire in...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>There's an emergency evacuation happening now ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I'm afraid that the tornado is coming to our a...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Lets try LSTM model to make predictions","metadata":{}},{"cell_type":"markdown","source":"For a person reading the tweets, its quite easy to understand which is a disaster and which one is not.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2022-04-03T22:04:48.001401Z","iopub.execute_input":"2022-04-03T22:04:48.001984Z","iopub.status.idle":"2022-04-03T22:04:55.464673Z","shell.execute_reply.started":"2022-04-03T22:04:48.001937Z","shell.execute_reply":"2022-04-03T22:04:55.463634Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"We train our model on only the text column.","metadata":{}},{"cell_type":"code","source":"training_sentences = X_train_full['text']\nvalidation_sentences = X_valid_full['text']\ntraining_labels = y_train\nvalidation_labels = y_valid","metadata":{"execution":{"iopub.status.busy":"2022-04-03T22:10:37.414955Z","iopub.execute_input":"2022-04-03T22:10:37.415287Z","iopub.status.idle":"2022-04-03T22:10:37.420776Z","shell.execute_reply.started":"2022-04-03T22:10:37.415252Z","shell.execute_reply":"2022-04-03T22:10:37.419812Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}